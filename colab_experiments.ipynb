{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masoudcharkhabi/ML-from-Expert-Preferences/blob/abstractions/abstractions/colab_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "zuDTEufZrEYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Packages"
      ],
      "metadata": {
        "id": "PHMCnbkcCdFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from getpass import getpass\n",
        "import wandb\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Disable TensorFlow info, warning, and error messages.\n"
      ],
      "metadata": {
        "id": "4z1b_U1ucl7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Huggingface login"
      ],
      "metadata": {
        "id": "lb4OWdXec8C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for Hugging Face API token without saving it\n",
        "huggingface_token = getpass(\"Please enter your Hugging Face API token: \")\n",
        "\n",
        "# Set the token as an environment variable\n",
        "os.environ[\"HUGGINGFACE_TOKEN\"] = huggingface_token\n",
        "\n",
        "# Log in using the token\n",
        "from huggingface_hub import login\n",
        "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kRzh2P_cscd",
        "outputId": "f4bec7b7-ed0c-438b-dfad-6fa21099cb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Hugging Face API token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make sure you have a GPU and High memory"
      ],
      "metadata": {
        "id": "FBnUlJkFDZc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v10tOBD5rFcA",
        "outputId": "9b85e4eb-d3bf-422e-ac3e-102c3b0d776f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  4 05:05:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0              30W /  70W |   2735MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rnSFGIj5APcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone Github repo (you need private-public keys with the same naming convention)"
      ],
      "metadata": {
        "id": "401jtOTODD7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create symbolic links to the SSH keys in Drive\n",
        "!ln -s /content/drive/MyDrive/ssh_keys/id_colab ~/.ssh/id_colab\n",
        "!ln -s /content/drive/MyDrive/ssh_keys/id_colab.pub ~/.ssh/id_colab.pub\n",
        "\n",
        "# Set the correct permissions for SSH keys\n",
        "!chmod 600 ~/.ssh/id_colab\n",
        "!chmod 644 ~/.ssh/id_colab.pub\n",
        "\n",
        "# Start SSH agent and add key\n",
        "!eval \"$(ssh-agent -s)\"\n",
        "!ssh-add ~/.ssh/id_colab\n",
        "\n",
        "# Create SSH config\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  HostName github.com\n",
        "  User git\n",
        "  IdentityFile ~/.ssh/id_colab\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "# Create the .ssh directory if it doesn't exist\n",
        "os.makedirs(os.path.expanduser(\"~/.ssh\"), exist_ok=True)\n",
        "\n",
        "with open(os.path.expanduser(\"~/.ssh/config\"), \"w\") as f:\n",
        "    f.write(ssh_config)\n",
        "\n",
        "# Test SSH connection\n",
        "!ssh -T git@github.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1egWyduzASgZ",
        "outputId": "dba7e97b-4cdc-4dd4-ce90-3b122ed4264b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ln: failed to create symbolic link '/root/.ssh/id_colab': File exists\n",
            "ln: failed to create symbolic link '/root/.ssh/id_colab.pub': File exists\n",
            "Agent pid 44810\n",
            "Could not open a connection to your authentication agent.\n",
            "Hi masoudcharkhabi! You've successfully authenticated, but GitHub does not provide shell access.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_ssh_url = \"git@github.com:masoudcharkhabi/ML-from-Expert-Preferences.git\"\n",
        "branch_name = \"colab\"\n",
        "!git clone -b {branch_name} --single-branch {repo_ssh_url}"
      ],
      "metadata": {
        "id": "dMUqzX1JrILL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cb41db-b11b-4947-a73a-a39d1dd89ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML-from-Expert-Preferences'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 261 (delta 9), reused 13 (delta 6), pack-reused 233 (from 1)\u001b[K\n",
            "Receiving objects: 100% (261/261), 348.16 KiB | 1.32 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"ML-from-Expert-Preferences\"\n",
        "os.chdir(repo_name)"
      ],
      "metadata": {
        "id": "gF1ieVq3BJj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch\n",
        "!ls -ltr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afxaCnjJBihb",
        "outputId": "ffac78d5-c682-4b05-9a59-96da08c31376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mcolab\u001b[m\n",
            "total 20\n",
            "-rw-r--r-- 1 root root 2680 Dec  4 04:17 README.md\n",
            "drwxr-xr-x 3 root root 4096 Dec  4 04:17 baseline\n",
            "drwxr-xr-x 4 root root 4096 Dec  4 04:17 cs329h-project\n",
            "drwxr-xr-x 5 root root 4096 Dec  4 04:17 data\n",
            "-rw-r--r-- 1 root root  155 Dec  4 04:17 requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYNMV0vHFyG7",
        "outputId": "e0a3bca1-89e4-418b-8df5-1efe74d5e165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.46.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.26.2)\n",
            "Requirement already satisfied: pytest>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (8.3.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: rouge-score>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->-r requirements.txt (line 2)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->-r requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 2)) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->-r requirements.txt (line 2)) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->-r requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.0.0->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.0.0->-r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.0.0->-r requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.0.0->-r requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 7)) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.1.2->-r requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.0.0->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.0.0->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.0.0->-r requirements.txt (line 2)) (2024.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data prep"
      ],
      "metadata": {
        "id": "wbtHKzO_Xeue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_prep.py\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "class DataPreparation:\n",
        "    def __init__(self, dataset_path: str):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.dataset = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load dataset from Hugging Face\"\"\"\n",
        "        self.dataset = load_dataset(self.dataset_path)\n",
        "        return self.dataset\n",
        "\n",
        "    def preprocess(self, example):\n",
        "        \"\"\"Preprocess dataset into input-output pairs\"\"\"\n",
        "        return {\n",
        "            \"input_text\": example['inputs'],\n",
        "            \"target_text\": example['targets'],\n",
        "        }\n",
        "\n",
        "    def tokenize_function(self, examples, tokenizer):\n",
        "        \"\"\"Tokenize input and output text\"\"\"\n",
        "        model_inputs = tokenizer(\n",
        "            examples[\"input_text\"],\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "        labels = tokenizer(\n",
        "            examples[\"target_text\"],\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    def prepare_dataset(self, tokenizer):\n",
        "        \"\"\"Prepare the dataset for training\"\"\"\n",
        "        train_dataset = self.dataset[\"train\"].map(self.preprocess)\n",
        "        train_dataset = train_dataset.map(lambda x: self.tokenize_function(x, tokenizer), batched=True)\n",
        "        eval_dataset = self.dataset[\"validation\"].map(self.preprocess) if \"validation\" in self.dataset else None\n",
        "        eval_dataset = eval_dataset.map(lambda x: self.tokenize_function(x, tokenizer), batched=True) if eval_dataset else None\n",
        "        # Return only train_dataset instead of a tuple\n",
        "        return train_dataset\n",
        "\n",
        "    def dataset_info(self):\n",
        "        \"\"\"Print information about the dataset, such as the size\"\"\"\n",
        "        if self.dataset:\n",
        "            for split in self.dataset.keys():\n",
        "                print(f\"Split: {split}, Number of examples: {len(self.dataset[split])}\")\n",
        "        else:\n",
        "            print(\"Dataset is not loaded. Please call load_data() first.\")"
      ],
      "metadata": {
        "id": "OGL6_3IjXnav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# from data_prep import DataPreparation\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")  # Replace \"t5-small\" with the appropriate model name\n",
        "\n",
        "# Create instance of DataPreparation\n",
        "data_preparation = DataPreparation(dataset_path=\"ai2-adapt-dev/flan_v2_converted\")\n",
        "\n",
        "# Load the dataset\n",
        "dataset = data_preparation.load_data()\n",
        "\n",
        "# Prepare the dataset (tokenize)\n",
        "train_dataset = data_preparation.prepare_dataset(tokenizer=tokenizer)\n",
        "\n",
        "# Now train_dataset is ready for training\n",
        "# Get dataset information\n",
        "data_preparation.dataset_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGGjFifeYPQa",
        "outputId": "04aea976-5f51-408b-ccba-177b4bebf549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split: train, Number of examples: 89982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune"
      ],
      "metadata": {
        "id": "GLmHG-UzFvYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This will require and Weights and Biases API key for logging"
      ],
      "metadata": {
        "id": "Pp1zs7NVxHfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "\n",
        "import os\n",
        "import wandb\n",
        "import datetime\n",
        "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model_name = model_name\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        self.trainer = None\n",
        "        self.experiment_id = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        self.output_dir = f\"./models/fine_tuned_model_{self.experiment_id}\"\n",
        "        wandb.init(project=\"active-llm\", name=f\"fine_tune_{self.experiment_id}\", resume=\"allow\")\n",
        "\n",
        "    def setup_training(self, train_dataset, eval_dataset=None, tokenizer=None):\n",
        "        \"\"\"Set up training arguments and Trainer\"\"\"\n",
        "        # Ensure the output directory exists\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=self.output_dir,\n",
        "            eval_strategy=\"epoch\" if eval_dataset is not None else \"no\",\n",
        "            learning_rate=2e-5,\n",
        "            per_device_train_batch_size=2,\n",
        "            per_device_eval_batch_size=2,\n",
        "            num_train_epochs=0.0005,\n",
        "            weight_decay=0.01,\n",
        "            report_to=[\"wandb\"],  # Log training statistics to Weights & Biases\n",
        "            run_name=\"model_training\"\n",
        "        )\n",
        "\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "        )\n",
        "\n",
        "    def train_model(self, save_model: bool = True):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        if self.trainer is not None:\n",
        "            self.trainer.train()\n",
        "            if save_model:\n",
        "                # Ensure the output directory exists before saving\n",
        "                os.makedirs(self.output_dir, exist_ok=True)\n",
        "                self.trainer.save_model(self.output_dir)\n",
        "                print(f\"Model saved to: {self.output_dir}\")\n",
        "            wandb.finish()\n",
        "        else:\n",
        "            raise ValueError(\"Trainer is not initialized. Please call setup_training first.\")\n"
      ],
      "metadata": {
        "id": "KNc_b6u0Zt_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes\n",
        "from transformers import AutoTokenizer\n",
        "# from data_prep import DataPreparation\n",
        "# from train import ModelTrainer\n",
        "\n",
        "# Step 1: Load tokenizer\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Load and prepare the dataset\n",
        "data_preparation = DataPreparation(dataset_path=\"ai2-adapt-dev/flan_v2_converted\")\n",
        "dataset = data_preparation.load_data()\n",
        "train_dataset = data_preparation.prepare_dataset(tokenizer=tokenizer)\n",
        "\n",
        "# Step 3: Initialize ModelTrainer and setup training\n",
        "trainer = ModelTrainer(model_name=model_name)\n",
        "trainer.setup_training(train_dataset=train_dataset, tokenizer=tokenizer)\n",
        "\n",
        "# Step 4: Train the model\n",
        "trainer.train_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "qb6lFqjNZ0Rw",
        "outputId": "74fbdd84-ae2e-4d82-d543-da8548d82dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:zuatuk5g) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fine_tune_20241204_050622</strong> at: <a href='https://wandb.ai/ai-eval/active-llm/runs/zuatuk5g' target=\"_blank\">https://wandb.ai/ai-eval/active-llm/runs/zuatuk5g</a><br/> View project at: <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">https://wandb.ai/ai-eval/active-llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241204_050622-zuatuk5g/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:zuatuk5g). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/ML-from-Expert-Preferences/ML-from-Expert-Preferences/wandb/run-20241204_050641-65r6z8tp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ai-eval/active-llm/runs/65r6z8tp' target=\"_blank\">fine_tune_20241204_050641</a></strong> to <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">https://wandb.ai/ai-eval/active-llm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ai-eval/active-llm/runs/65r6z8tp' target=\"_blank\">https://wandb.ai/ai-eval/active-llm/runs/65r6z8tp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-a8f77495dbc4>:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  self.trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:05, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: ./models/fine_tuned_model_20241204_050641\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>6225722867712.0</td></tr><tr><td>train/epoch</td><td>0.00051</td></tr><tr><td>train/global_step</td><td>23</td></tr><tr><td>train_loss</td><td>17.81372</td></tr><tr><td>train_runtime</td><td>5.6087</td></tr><tr><td>train_samples_per_second</td><td>8.022</td></tr><tr><td>train_steps_per_second</td><td>4.101</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fine_tune_20241204_050641</strong> at: <a href='https://wandb.ai/ai-eval/active-llm/runs/65r6z8tp' target=\"_blank\">https://wandb.ai/ai-eval/active-llm/runs/65r6z8tp</a><br/> View project at: <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">https://wandb.ai/ai-eval/active-llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241204_050641-65r6z8tp/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serve"
      ],
      "metadata": {
        "id": "DFBWN5Ljet3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# serve.py\n",
        "\n",
        "import torch\n",
        "\n",
        "class ModelServer:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model_name = model_name\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        self.tokenizer = None\n",
        "\n",
        "    def set_tokenizer(self, tokenizer):\n",
        "        \"\"\"Set the tokenizer for the model\"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def run_inference(self, input_text: str):\n",
        "        \"\"\"Generate output for a given input text\"\"\"\n",
        "        if self.tokenizer is None:\n",
        "            raise ValueError(\"Tokenizer not set. Please use set_tokenizer method.\")\n",
        "\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
        "        outputs = self.model.generate(**inputs)\n",
        "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    def store_output(self, input_text: str, output_path: str):\n",
        "        \"\"\"Store the generated output in a file\"\"\"\n",
        "        output = self.run_inference(input_text)\n",
        "        with open(output_path, \"w\") as file:\n",
        "            file.write(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "maH8KVGuetLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# from serve import ModelServer\n",
        "\n",
        "# Step 1: Load the tokenizer\n",
        "model_name = \"t5-small\"  # TODO: Replace with fine-tuned model later\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Initialize ModelServer\n",
        "model_server = ModelServer(model_name=model_name)\n",
        "\n",
        "# Step 3: Set the tokenizer for the model server\n",
        "model_server.set_tokenizer(tokenizer)\n",
        "\n",
        "# Step 4: Run inference\n",
        "input_text = \"Translate the following sentence to French: 'The weather is nice today.'\"\n",
        "output_text = model_server.run_inference(input_text)\n",
        "\n",
        "# Step 5: Print the result\n",
        "print(\"Generated Output:\", output_text)\n",
        "\n",
        "# Optional: Store the output in a file\n",
        "experiment_id = \"a1005\"\n",
        "output_path = \"./data/output/\"+experiment_id+\"_output.txt\"\n",
        "model_server.store_output(input_text, output_path)\n",
        "print(f\"Output stored in: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luxlv83xmQPi",
        "outputId": "3e31b024-b0c9-4935-b670-ab765264e2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: « Le temps est agréable aujourd'hui ».\n",
            "Output stored in: ./data/output/a1005_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval"
      ],
      "metadata": {
        "id": "QiFgVgblepEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eval.py\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from evaluate import load\n",
        "import torch\n",
        "import wandb\n",
        "import numpy as np\n",
        "import datetime\n",
        "from random import sample\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, model_name: str, tokenizer):\n",
        "        self.model_name = model_name\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bleu_metric = load(\"bleu\")\n",
        "        self.rouge_metric = load(\"rouge\")\n",
        "        self.experiment_id = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        wandb.init(project=\"active-llm\", name=f\"eval_{self.experiment_id}\", resume=\"allow\")\n",
        "\n",
        "    def evaluate(self, dataset, sample_size=100, batch_size=8):\n",
        "        \"\"\"Evaluate model performance on a subset of the dataset using batches\"\"\"\n",
        "        # Sample a subset of the dataset to speed up evaluation\n",
        "        if len(dataset) > sample_size:\n",
        "            dataset = sample(list(dataset), sample_size)\n",
        "\n",
        "        predictions = []\n",
        "        references = []\n",
        "        total_loss = 0\n",
        "        num_tokens = 0\n",
        "\n",
        "        for i in range(0, len(dataset), batch_size):\n",
        "            batch = dataset[i:i + batch_size]\n",
        "            input_texts = [example[\"input_text\"] for example in batch]\n",
        "            target_texts = [example[\"target_text\"] for example in batch]\n",
        "\n",
        "            inputs = self.tokenizer(input_texts, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=100)\n",
        "            labels = self.tokenizer(target_texts, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=100).input_ids\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(**inputs, max_length=100)\n",
        "                predicted_texts = [self.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "                predictions.extend(predicted_texts)\n",
        "                references.extend(target_texts)\n",
        "\n",
        "                # Calculate loss for perplexity in a batch\n",
        "                output_loss = self.model(**inputs, labels=labels)\n",
        "                total_loss += output_loss.loss.item() * labels.size(1)\n",
        "                num_tokens += labels.size(1)\n",
        "\n",
        "        # Calculate traditional metrics\n",
        "        accuracy = accuracy_score(references, predictions)\n",
        "        f1 = f1_score(references, predictions, average='weighted')\n",
        "        precision = precision_score(references, predictions, average='weighted')\n",
        "        recall = recall_score(references, predictions, average='weighted')\n",
        "\n",
        "        # Calculate LLM and NLP specific metrics\n",
        "        bleu_score = self.bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])\n",
        "        rouge_score = self.rouge_metric.compute(predictions=predictions, references=references)\n",
        "\n",
        "        # Calculate perplexity\n",
        "        avg_loss = total_loss / num_tokens\n",
        "        perplexity = torch.exp(torch.tensor(avg_loss))\n",
        "\n",
        "        # Log the results to W&B\n",
        "        wandb.log({\n",
        "            \"accuracy\": accuracy,\n",
        "            \"f1_score\": f1,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"bleu\": bleu_score,\n",
        "            \"rouge\": rouge_score,\n",
        "            \"perplexity\": perplexity.item(),\n",
        "                    })\n",
        "        wandb.finish()\n",
        "\n",
        "        return {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"f1_score\": f1,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"bleu\": bleu_score,\n",
        "            \"rouge\": rouge_score,\n",
        "            \"perplexity\": perplexity.item()\n",
        "        }\n"
      ],
      "metadata": {
        "id": "ouQuMcW2er6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# from data_prep import DataPreparation\n",
        "# from eval import ModelEvaluator\n",
        "\n",
        "# Step 1: Load the tokenizer\n",
        "model_name = \"t5-small\"\n",
        "\n",
        "# TODO: Replace with  fine-tuned model path (including the correct timestamp) later\n",
        "# model_name = \"./fine_tuned_model_20231124_123456\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Create instance of DataPreparation and load the dataset\n",
        "data_preparation = DataPreparation(dataset_path=\"ai2-adapt-dev/flan_v2_converted\")\n",
        "dataset = data_preparation.load_data()\n",
        "\n",
        "# Step 3: Prepare evaluation dataset\n",
        "eval_dataset = data_preparation.prepare_dataset(tokenizer=tokenizer)\n",
        "\n",
        "# Step 4: Initialize ModelEvaluator\n",
        "evaluator = ModelEvaluator(model_name=model_name, tokenizer=tokenizer)\n",
        "\n",
        "# Step 5: Run evaluation\n",
        "evaluation_results = evaluator.evaluate(eval_dataset)\n",
        "\n",
        "# Step 6: Print the evaluation results\n",
        "print(\"Evaluation Results:\", evaluation_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "s_VKPbo5nYDh",
        "outputId": "d7a6341d-9f32-487a-ef0d-10c15eb4440d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/ML-from-Expert-Preferences/ML-from-Expert-Preferences/wandb/run-20241204_043214-j22w89y3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ai-eval/active-llm/runs/j22w89y3' target=\"_blank\">eval_20241204_043214</a></strong> to <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">https://wandb.ai/ai-eval/active-llm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ai-eval/active-llm/runs/j22w89y3' target=\"_blank\">https://wandb.ai/ai-eval/active-llm/runs/j22w89y3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>perplexity</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0</td></tr><tr><td>f1_score</td><td>0</td></tr><tr><td>perplexity</td><td>76779512.0</td></tr><tr><td>precision</td><td>0</td></tr><tr><td>recall</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eval_20241204_043214</strong> at: <a href='https://wandb.ai/ai-eval/active-llm/runs/j22w89y3' target=\"_blank\">https://wandb.ai/ai-eval/active-llm/runs/j22w89y3</a><br/> View project at: <a href='https://wandb.ai/ai-eval/active-llm' target=\"_blank\">https://wandb.ai/ai-eval/active-llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241204_043214-j22w89y3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'accuracy': 0.0, 'f1_score': 0.0, 'precision': 0.0, 'recall': 0.0, 'bleu': {'bleu': 0.03550836856172761, 'precisions': [0.11895388076490439, 0.03905120046282904, 0.023435182438445563, 0.014602981442044418], 'brevity_penalty': 1.0, 'length_ratio': 1.2912127814088599, 'translation_length': 3556, 'reference_length': 2754}, 'rouge': {'rouge1': 0.10575423600418363, 'rouge2': 0.03249340922976353, 'rougeL': 0.0822570979963348, 'rougeLsum': 0.08913628656954073}, 'perplexity': 76779512.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYD_kb0Vx8bP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}