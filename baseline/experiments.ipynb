{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOo8bv340qZ1O6MmwODvJRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masoudcharkhabi/ML-from-Expert-Preferences/blob/colab/baseline/experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "zuDTEufZrEYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make sure you have a GPU and High memory"
      ],
      "metadata": {
        "id": "FBnUlJkFDZc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v10tOBD5rFcA",
        "outputId": "3a2b3ec9-d3aa-4ecc-dcc7-b99a884dcb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  3 04:00:29 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rnSFGIj5APcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drive mount and SSH keys (id_colab) for Github"
      ],
      "metadata": {
        "id": "PHMCnbkcCdFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create symbolic links to the SSH keys in Drive\n",
        "!ln -s /content/drive/MyDrive/ssh_keys/id_colab ~/.ssh/id_colab\n",
        "!ln -s /content/drive/MyDrive/ssh_keys/id_colab.pub ~/.ssh/id_colab.pub\n",
        "\n",
        "# Set the correct permissions for SSH keys\n",
        "!chmod 600 ~/.ssh/id_colab\n",
        "!chmod 644 ~/.ssh/id_colab.pub\n",
        "\n",
        "# Start SSH agent and add key\n",
        "!eval \"$(ssh-agent -s)\"\n",
        "!ssh-add ~/.ssh/id_colab\n",
        "\n",
        "# Create SSH config\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  HostName github.com\n",
        "  User git\n",
        "  IdentityFile ~/.ssh/id_colab\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.expanduser(\"~/.ssh/config\"), \"w\") as f:\n",
        "    f.write(ssh_config)\n",
        "\n",
        "# Test SSH connection\n",
        "!ssh -T git@github.com"
      ],
      "metadata": {
        "id": "1egWyduzASgZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVcW1-YK-B-3",
        "outputId": "c54be1c6-8688-4c8b-a67d-353278715494"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone Github repo"
      ],
      "metadata": {
        "id": "401jtOTODD7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_ssh_url = \"git@github.com:masoudcharkhabi/ML-from-Expert-Preferences.git\"\n",
        "branch_name = \"colab\"\n",
        "!git clone -b {branch_name} --single-branch {repo_ssh_url}"
      ],
      "metadata": {
        "id": "dMUqzX1JrILL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585466eb-7314-447a-e9f8-f50e26b08785"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML-from-Expert-Preferences'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 175 (delta 85), reused 110 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (175/175), 314.28 KiB | 467.00 KiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"ML-from-Expert-Preferences\"\n",
        "os.chdir(repo_name)"
      ],
      "metadata": {
        "id": "gF1ieVq3BJj1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afxaCnjJBihb",
        "outputId": "b86fdae8-cab0-4601-f7ac-cf1e154073c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mcolab\u001b[m\n"
          ]
        }
      ]
    }
  ]
}